/**
 * face-api.jsë¥¼ ì‚¬ìš©í•œ ì–¼êµ´ ì¸ì‹ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 * 1. ëª¨ë¸ ë¡œë“œ: face-api.jsì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ë“¤ì„ ë¡œë“œ
 * 2. ì–¼êµ´ ê²€ì¶œ: ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ê³  descriptor ì¶”ì¶œ
 * 3. ê±°ë¦¬ ê³„ì‚°: ë‘ ì–¼êµ´ descriptor ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
 * 4. ë§¤ì¹­: ê¸°ì¤€ ì–¼êµ´ê³¼ ìœ ì‚¬í•œ ì–¼êµ´ì´ ìˆëŠ” ì‚¬ì§„ ì°¾ê¸°
 */

import * as faceapi from "face-api.js";
import {
  DetectedFace,
  MarathonPhoto,
  MatchResult,
  Expression,
  FaceExpressions,
} from "./types";

/**
 * face-api.js ëª¨ë¸ë“¤ì„ public/models ê²½ë¡œì—ì„œ ë¡œë“œ
 * í•„ìš”í•œ ëª¨ë¸:
 * - TinyFaceDetector: ê°€ë²¼ìš´ ì–¼êµ´ ê²€ì¶œ ëª¨ë¸
 * - FaceLandmark68Net: ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ (68ê°œ í¬ì¸íŠ¸)
 * - FaceRecognitionNet: ì–¼êµ´ descriptor(ì„ë² ë”©) ì¶”ì¶œ
 * - FaceExpressionNet: ì–¼êµ´ í‘œì • ì¸ì‹ (7ê°€ì§€ ê°ì •)
 * - AgeGenderNet: ë‚˜ì´ ë° ì„±ë³„ ì¶”ì •
 *
 * @returns Promise<void>
 */
export async function loadModels(): Promise<void> {
  const MODEL_URL = "/models";

  await Promise.all([
    faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
    faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
    faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
    faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),
    faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),
  ]);
}

/**
 * ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
 * ê¸´ ë³€ ê¸°ì¤€ìœ¼ë¡œ maxSizeë¡œ ì¶•ì†Œ
 *
 * @param img - HTMLImageElement
 * @param maxSize - ìµœëŒ€ í¬ê¸° (ê¸°ë³¸ 800px)
 * @returns ë¦¬ì‚¬ì´ì¦ˆëœ HTMLCanvasElement
 */
function resizeImage(
  img: HTMLImageElement,
  maxSize: number = 800
): HTMLCanvasElement {
  const canvas = document.createElement("canvas");
  const ctx = canvas.getContext("2d")!;

  let width = img.width;
  let height = img.height;

  // ê¸´ ë³€ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
  if (width > height && width > maxSize) {
    height = (height * maxSize) / width;
    width = maxSize;
  } else if (height > maxSize) {
    width = (width * maxSize) / height;
    height = maxSize;
  }

  canvas.width = width;
  canvas.height = height;
  ctx.drawImage(img, 0, 0, width, height);

  return canvas;
}

/**
 * ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ ì–¼êµ´ë“¤ì„ ê²€ì¶œí•˜ê³  descriptor ì¶”ì¶œ
 *
 * ì²˜ë¦¬ ê³¼ì •:
 * 1. File ê°ì²´ë¥¼ HTMLImageElementë¡œ ë³€í™˜
 * 2. ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
 * 3. face-api.jsë¡œ ì–¼êµ´ ê²€ì¶œ + ëœë“œë§ˆí¬ + descriptor ì¶”ì¶œ
 * 4. ê²€ì¶œëœ ê° ì–¼êµ´ì˜ descriptorì™€ bounding box ë°˜í™˜
 *
 * @param file - ì´ë¯¸ì§€ íŒŒì¼
 * @returns Promise<DetectedFace[]> - ê²€ì¶œëœ ì–¼êµ´ë“¤ì˜ ë°°ì—´
 */
export async function detectFacesInImage(file: File): Promise<DetectedFace[]> {
  return new Promise((resolve, reject) => {
    const img = document.createElement("img");
    const objectUrl = URL.createObjectURL(file);

    img.onload = async () => {
      try {
        // ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆë¡œ ì„±ëŠ¥ ìµœì í™”
        const resizedCanvas = resizeImage(img, 800);

        // ì–¼êµ´ ê²€ì¶œ + ëœë“œë§ˆí¬ + descriptor + í‘œì • + ë‚˜ì´/ì„±ë³„ ì¶”ì¶œ
        // withFaceLandmarks: ì–¼êµ´ì˜ 68ê°œ ëœë“œë§ˆí¬ í¬ì¸íŠ¸ ê²€ì¶œ
        // withFaceDescriptors: ì–¼êµ´ì˜ 128ì°¨ì› ë²¡í„° ì¶”ì¶œ
        // withFaceExpressions: 7ê°€ì§€ ê°ì • í™•ë¥  ì¶”ì¶œ
        // withAgeAndGender: ë‚˜ì´ ë° ì„±ë³„ ì¶”ì •
        const detections = await faceapi
          .detectAllFaces(resizedCanvas, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptors()
          .withFaceExpressions()
          .withAgeAndGender();

        // DetectedFace í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        const faces: DetectedFace[] = detections.map((detection) => ({
          descriptor: detection.descriptor,
          box: {
            x: detection.detection.box.x,
            y: detection.detection.box.y,
            width: detection.detection.box.width,
            height: detection.detection.box.height,
          },
          expressions: detection.expressions
            ? {
                happy: detection.expressions.happy,
                sad: detection.expressions.sad,
                angry: detection.expressions.angry,
                surprised: detection.expressions.surprised,
                disgusted: detection.expressions.disgusted,
                fearful: detection.expressions.fearful,
                neutral: detection.expressions.neutral,
              }
            : undefined,
          age: detection.age,
          gender: detection.gender as "male" | "female",
          genderProbability: detection.genderProbability,
        }));

        URL.revokeObjectURL(objectUrl);
        resolve(faces);
      } catch (error) {
        URL.revokeObjectURL(objectUrl);
        reject(error);
      }
    };

    img.onerror = () => {
      URL.revokeObjectURL(objectUrl);
      reject(new Error("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨"));
    };

    img.src = objectUrl;
  });
}

/**
 * ë‘ descriptor ê°„ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
 * ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ë‘ ì–¼êµ´ì´ ìœ ì‚¬í•¨
 *
 * @param desc1 - ì²« ë²ˆì§¸ ì–¼êµ´ì˜ descriptor
 * @param desc2 - ë‘ ë²ˆì§¸ ì–¼êµ´ì˜ descriptor
 * @returns number - ìœ í´ë¦¬ë“œ ê±°ë¦¬ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
 */
export function calculateDistance(
  desc1: Float32Array,
  desc2: Float32Array
): number {
  return faceapi.euclideanDistance(desc1, desc2);
}

/**
 * ê¸°ì¤€ ì–¼êµ´ê³¼ ë§¤ì¹­ë˜ëŠ” ì‚¬ì§„ë“¤ì„ ì°¾ê¸°
 *
 * ì²˜ë¦¬ ê³¼ì •:
 * 1. ê° ëŒ€íšŒ ì‚¬ì§„ì˜ ëª¨ë“  ì–¼êµ´ë“¤ê³¼ ê¸°ì¤€ ì–¼êµ´ì˜ ê±°ë¦¬ ê³„ì‚°
 * 2. ì‚¬ì§„ë‹¹ ê°€ì¥ ê°€ê¹Œìš´ ê±°ë¦¬ë¥¼ ëŒ€í‘œ ê±°ë¦¬ë¡œ ì‚¬ìš©
 * 3. threshold ì´í•˜ì¸ ì‚¬ì§„ë§Œ ë§¤ì¹­ìœ¼ë¡œ ê°„ì£¼
 * 4. score = max(0, 1 - distance)ë¡œ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
 * 5. score ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
 *
 * @param myDescriptor - ë‚´ ì–¼êµ´ì˜ descriptor
 * @param photos - ëŒ€íšŒ ì‚¬ì§„ë“¤ (ì–¼êµ´ ê²€ì¶œ ì™„ë£Œëœ ìƒíƒœ)
 * @param threshold - ë§¤ì¹­ íŒë‹¨ ì„ê³„ê°’ (ê¸°ë³¸ 0.6, ë‚®ì„ìˆ˜ë¡ ì—„ê²©)
 * @returns MatchResult[] - ë§¤ì¹­ëœ ì‚¬ì§„ë“¤ (score ë‚´ë¦¼ì°¨ìˆœ)
 */
export function findMatchingPhotos(
  myDescriptor: Float32Array,
  photos: MarathonPhoto[],
  threshold: number = 0.6
): MatchResult[] {
  const results: MatchResult[] = [];

  // ê° ì‚¬ì§„ì— ëŒ€í•´ ì²˜ë¦¬
  for (const photo of photos) {
    // ì´ ì‚¬ì§„ì—ì„œ ê²€ì¶œëœ ì–¼êµ´ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if (photo.faces.length === 0) {
      continue;
    }

    // ì´ ì‚¬ì§„ì˜ ëª¨ë“  ì–¼êµ´ë“¤ê³¼ ë‚´ ì–¼êµ´ì˜ ê±°ë¦¬ ê³„ì‚°
    const distances = photo.faces.map((face) =>
      calculateDistance(myDescriptor, face.descriptor)
    );

    // ê°€ì¥ ê°€ê¹Œìš´ ê±°ë¦¬ (ê°€ì¥ ìœ ì‚¬í•œ ì–¼êµ´)
    const minDistance = Math.min(...distances);

    // threshold ì´í•˜ì¸ ê²½ìš°ë§Œ ë§¤ì¹­ìœ¼ë¡œ ê°„ì£¼
    if (minDistance <= threshold) {
      // ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°: ê±°ë¦¬ê°€ 0ì´ë©´ 100%, 1ì´ë©´ 0%
      const score = Math.max(0, 1 - minDistance);

      results.push({
        photo,
        distance: minDistance,
        score,
      });
    }
  }

  // score ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ì§„ì´ ë¨¼ì €)
  results.sort((a, b) => b.score - a.score);

  return results;
}

/**
 * ê¸°ì¤€ ì‚¬ì§„ì—ì„œ ì–¼êµ´ 1ê°œ ì¶”ì¶œ
 * ì—¬ëŸ¬ ì–¼êµ´ì´ ê²€ì¶œë˜ë©´ ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
 *
 * @param file - ê¸°ì¤€ ì–¼êµ´ ì‚¬ì§„ íŒŒì¼
 * @returns Promise<Float32Array | null> - ì–¼êµ´ descriptor (ê²€ì¶œ ì‹¤íŒ¨ ì‹œ null)
 */
export async function extractReferenceFace(
  file: File
): Promise<Float32Array | null> {
  const faces = await detectFacesInImage(file);

  if (faces.length === 0) {
    return null;
  }

  // ì—¬ëŸ¬ ì–¼êµ´ì´ ê²€ì¶œë˜ë©´ ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
  if (faces.length > 1) {
    faces.sort((a, b) => {
      const areaA = a.box.width * a.box.height;
      const areaB = b.box.width * b.box.height;
      return areaB - areaA;
    });
  }

  return faces[0].descriptor;
}

/**
 * í‘œì •ì—ì„œ ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í‘œì • ë°˜í™˜
 *
 * @param expressions - í‘œì • í™•ë¥  ê°ì²´
 * @returns Expression - ê°€ì¥ í™•ë¥ ì´ ë†’ì€ í‘œì •
 */
export function getDominantExpression(
  expressions: FaceExpressions
): Expression {
  const entries = Object.entries(expressions) as [Expression, number][];
  const sorted = entries.sort((a, b) => b[1] - a[1]);
  return sorted[0][0];
}

/**
 * í‘œì •ì„ ì´ëª¨ì§€ë¡œ ë³€í™˜
 *
 * @param expression - í‘œì • íƒ€ì…
 * @returns string - í•´ë‹¹í•˜ëŠ” ì´ëª¨ì§€
 */
export function getExpressionEmoji(expression: Expression): string {
  const emojiMap: Record<Expression, string> = {
    happy: "ğŸ˜Š",
    sad: "ğŸ˜¢",
    angry: "ğŸ˜ ",
    surprised: "ğŸ˜²",
    disgusted: "ğŸ¤¢",
    fearful: "ğŸ˜¨",
    neutral: "ğŸ˜",
  };
  return emojiMap[expression];
}

/**
 * í‘œì •ì„ í•œê¸€ë¡œ ë³€í™˜
 *
 * @param expression - í‘œì • íƒ€ì…
 * @returns string - í•œê¸€ í‘œì •ëª…
 */
export function getExpressionLabel(expression: Expression): string {
  const labelMap: Record<Expression, string> = {
    happy: "í–‰ë³µ",
    sad: "ìŠ¬í””",
    angry: "í™”ë‚¨",
    surprised: "ë†€ëŒ",
    disgusted: "í˜ì˜¤",
    fearful: "ë‘ë ¤ì›€",
    neutral: "ë¬´í‘œì •",
  };
  return labelMap[expression];
}

/**
 * ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ì˜ì—­ë§Œ í¬ë¡­
 *
 * @param imageUrl - ì›ë³¸ ì´ë¯¸ì§€ URL
 * @param box - ì–¼êµ´ bounding box
 * @param padding - ì—¬ë°± ë¹„ìœ¨ (ê¸°ë³¸ 0.2 = 20%)
 * @returns Promise<Blob> - í¬ë¡­ëœ ì´ë¯¸ì§€ Blob
 */
export async function cropFaceFromImage(
  imageUrl: string,
  box: { x: number; y: number; width: number; height: number },
  padding: number = 0.2
): Promise<Blob> {
  return new Promise((resolve, reject) => {
    const img = document.createElement("img");

    img.onload = () => {
      const canvas = document.createElement("canvas");
      const ctx = canvas.getContext("2d");

      if (!ctx) {
        reject(new Error("Canvas contextë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."));
        return;
      }

      // ì—¬ë°± ê³„ì‚°
      const paddingX = box.width * padding;
      const paddingY = box.height * padding;

      // í¬ë¡­ ì˜ì—­ ê³„ì‚° (ì—¬ë°± í¬í•¨, ì´ë¯¸ì§€ ê²½ê³„ ë„˜ì§€ ì•Šë„ë¡)
      const cropX = Math.max(0, box.x - paddingX);
      const cropY = Math.max(0, box.y - paddingY);
      const cropWidth = Math.min(img.width - cropX, box.width + paddingX * 2);
      const cropHeight = Math.min(
        img.height - cropY,
        box.height + paddingY * 2
      );

      // Canvas í¬ê¸° ì„¤ì •
      canvas.width = cropWidth;
      canvas.height = cropHeight;

      // ì´ë¯¸ì§€ í¬ë¡­í•˜ì—¬ ê·¸ë¦¬ê¸°
      ctx.drawImage(
        img,
        cropX,
        cropY,
        cropWidth,
        cropHeight,
        0,
        0,
        cropWidth,
        cropHeight
      );

      // Blobìœ¼ë¡œ ë³€í™˜
      canvas.toBlob(
        (blob) => {
          if (blob) {
            resolve(blob);
          } else {
            reject(new Error("ì´ë¯¸ì§€ë¥¼ Blobìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."));
          }
        },
        "image/jpeg",
        0.95
      );
    };

    img.onerror = () => {
      reject(new Error("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨"));
    };

    img.crossOrigin = "anonymous";
    img.src = imageUrl;
  });
}

/**
 * ì‚¬ì§„ì—ì„œ ëª¨ë“  ì–¼êµ´ì„ í¬ë¡­í•˜ì—¬ ë‹¤ìš´ë¡œë“œ
 *
 * @param photo - ë§ˆë¼í†¤ ì‚¬ì§„ ì •ë³´
 * @param faceIndex - íŠ¹ì • ì–¼êµ´ ì¸ë±ìŠ¤ (ì„ íƒì , ì—†ìœ¼ë©´ ëª¨ë“  ì–¼êµ´)
 */
export async function downloadCroppedFaces(
  photo: MarathonPhoto,
  faceIndex?: number
): Promise<void> {
  const facesToCrop =
    faceIndex !== undefined ? [photo.faces[faceIndex]] : photo.faces;

  if (facesToCrop.length === 0) {
    alert("í¬ë¡­í•  ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.");
    return;
  }

  try {
    for (let i = 0; i < facesToCrop.length; i++) {
      const face = facesToCrop[i];
      const blob = await cropFaceFromImage(photo.imageUrl, face.box);

      // ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
      const url = URL.createObjectURL(blob);
      const a = document.createElement("a");
      a.href = url;
      a.download = `face_${photo.file.name.replace(/\.[^/.]+$/, "")}_${
        i + 1
      }.jpg`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      URL.revokeObjectURL(url);

      // ë‹¤ì¤‘ ë‹¤ìš´ë¡œë“œ ì‹œ ì•½ê°„ì˜ ì§€ì—° (ë¸Œë¼ìš°ì € ì°¨ë‹¨ ë°©ì§€)
      if (facesToCrop.length > 1 && i < facesToCrop.length - 1) {
        await new Promise((resolve) => setTimeout(resolve, 100));
      }
    }
  } catch (error) {
    console.error("ì–¼êµ´ í¬ë¡­ ì‹¤íŒ¨:", error);
    alert("ì–¼êµ´ í¬ë¡­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
  }
}
